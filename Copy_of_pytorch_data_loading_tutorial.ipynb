{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulsubarna/BLIP/blob/main/Copy_of_pytorch_data_loading_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_yjsDNw_SVY"
      },
      "source": [
        "# ðŸ§  1.1. Introductory Tutorial\n",
        "\n",
        "In this introductory tutorial, we will revisit some of the fundamental concepts involved in training neural networks with PyTorch.\n",
        "\n",
        "To begin, we will re-familiarize ourselves with the process of loading data and working with PyTorchâ€™s built-in utilities.\n",
        "\n",
        "The tutorial will cover the following topics:\n",
        "1. Basic usage of PyTorch DataLoaders\n",
        "2. Loading and preprocessing built-in datasets (e.g., CIFAR-10, Imagenette)\n",
        "3. Creating a custom dataset class\n",
        "4. Applying data transformations\n",
        "5. Handling image and text data\n",
        "\n",
        "\n",
        "\n",
        "**TO-DO**\n",
        "1. Create a simple tensor dataset of arbitrary shape and load it using PyTorchâ€™s built-in utilities such as torch.utils.data.TensorDataset and DataLoader\n",
        "2. The DataLoader class provides several parameters that can affect performance. Can you think of ways to configure the same DataLoader to load data more efficiently (i.e., faster)?\n"
      ],
      "id": "C_yjsDNw_SVY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EJzC0ih_SVc",
        "outputId": "ed18fd1f-b153-476e-9b83-bfabc041911d"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Simple tensor data\n",
        "X =\n",
        "y =\n",
        "\n",
        "# Dataset and DataLoader\n",
        "dataset =\n",
        "loader = DataLoader()\n",
        "\n",
        "for batch_X, batch_y in loader:\n",
        "    print(batch_X.shape, batch_y.shape)\n",
        "    break\n",
        "\n",
        "** TO-DO **\n",
        "### Can you think of a way how to use the same DataLoader method to load the data faster?\n"
      ],
      "id": "5EJzC0ih_SVc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 3]) torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQQV0zZH_SVf"
      },
      "source": [
        "**Working with Images**\n",
        "\n",
        "We will explore different data modalities and learn how to load various types of data in PyTorch.\n",
        "1. The torchvision library provides several benchmark image datasets such as CIFAR-100, Imagenette, and others.\n",
        "2. Try loading one of these pre-built datasets and visualize a few sample images using Matplotlib."
      ],
      "id": "SQQV0zZH_SVf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "Uvw1O6Q6_SVh",
        "outputId": "1347cf9c-6b27-4025-8de7-23af3ca5ef5f"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "## TO-DO\n",
        "train_data = datasets.CIFAR10()\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=, pin_memory=, num_workers=)\n",
        "images, labels = next(iter(train_loader))\n",
        "print(images.shape, labels.shape)\n",
        "\n",
        "## Visualizing data samples\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "imshow(images[0])\n"
      ],
      "id": "Uvw1O6Q6_SVh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32]) torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqG7ukNe_SVh"
      },
      "source": [
        "\n",
        "Custom Dataset class\n",
        "=============\n",
        "However, in some cases, when the dataset is obtained from external sources, the built-in Dataset or DataLoader classes may not work as expected due to differences in the datasetâ€™s structure or format. To address this, we can define a custom Dataset subclass that inherits from PyTorchâ€™s Dataset class and adapts the loading process to our specific data layout\n",
        "\n",
        "`torch.utils.data.Dataset` is an abstract class representing a dataset.\n",
        "Your custom dataset should inherit `Dataset` and override the following\n",
        "methods:\n",
        "\n",
        "-   `__len__` so that `len(dataset)` returns the size of the dataset.\n",
        "-   `__getitem__` to support the indexing such that `dataset[i]` can be used to get ``i^th`` sample.\n",
        "\n",
        "Load the Imagenette dataset from PyTorch. You will notice that the directory is organized into multiple subfolders, each representing a class containing its corresponding image samples.\n",
        "\n",
        "In your custom dataset class, read the dataset structure inside the ``__init__`` method, but defer loading individual samples to the ``__getitem__`` method. This approach is memory-efficient since the data are not all loaded into memory at once, but accessed only when needed.\n",
        "\n",
        "Each sample in the dataset will be a tuple of (image, label).\n",
        "Additionally, our dataset class will include an optional transform argument, allowing you to apply preprocessing or data augmentation to each sample. We will discuss the importance and use of transform in the next cells."
      ],
      "id": "sqG7ukNe_SVh"
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/data/imagenette2/train\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "train_data = datasets.Imagenette(root='data', split=\"train\", download=True, transform=False)\n",
        "\n",
        "\n",
        "class ImageNet_Dataset(Dataset):\n",
        "  def __init__(self, image_directory, transform) -> None:\n",
        "      super().__init__()\n",
        "      self.transform = transform\n",
        "      self.image_directory =  image_directory\n",
        "      # Get the class labels from the directory names\n",
        "\n",
        "      ## TO-DO\n",
        "  def __len__(self):\n",
        "      return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "      ## TO-DO\n",
        "      return image, label"
      ],
      "metadata": {
        "id": "4iV_E9C8LEx2"
      },
      "id": "4iV_E9C8LEx2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforms\n",
        "==========\n",
        "\n",
        "One issue we can see from the above is that the samples are not of the\n",
        "same size. Since most neural networks expect inputs of a fixed dimension, we need to perform some preprocessing to standardize the image sizes.\n",
        "three transforms object with the built in PyTorch function `` transforms.Compose ``:\n",
        "\n",
        "Hint: Use augmentation techniques like Rescale, RandomCrop, RandomHorizontalFlip, ToTensor, etc.\n",
        "\n",
        "`` State``: Why are transformations such as RandomHorizontalFlip, ColorJitter for data helpful in data processing?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2CiIQjpaR6JQ"
      },
      "id": "2CiIQjpaR6JQ"
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose((\n",
        "\n",
        " ## TO-DO\n",
        "\n",
        " )\n",
        "\n",
        "\n",
        "imagenette = ImageNet_Dataset(\"your_image_directory\", transform=transform)\n",
        "dataloader = DataLoader(imagenette, batch_size=32, shuffle=True)\n",
        "images , labels = next(iter(dataloader))\n",
        "print(images.shape, labels.shape)"
      ],
      "metadata": {
        "id": "eYFweyL_NjTj"
      },
      "id": "eYFweyL_NjTj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CKzsGxG_SVk"
      },
      "source": [
        "## Working with texts\n",
        "\n",
        "Unlike image data, textual data requires a few additional preprocessing steps before it can be used for model training. You can build a custom vocabulary from your input corpus and design a tokenizer around it. However, there are also publicly available pretrained tokenizers (such as those in Hugging Face) that eliminate the need to create one from scratch.\n",
        "\n",
        "Following a similar approach to what we used for image data, letâ€™s now create a custom Dataset class for textual data to handle loading and preprocessing."
      ],
      "id": "-CKzsGxG_SVk"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "label2idx = {\"negative\": 0, \"positive\": 1}\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, label2idx, max_length=128):\n",
        "        self.samples = []\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label2idx = label2idx\n",
        "        self.max_length = max_length\n",
        "\n",
        "        ## TO-DO\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ## TO-DO\n",
        "        return item\n",
        "\n",
        "\n",
        "train_dataset = TextDataset(\"data/train.txt\", tokenizer, label2idx)\n",
        "val_dataset = TextDataset(\"data/val.txt\", tokenizer, label2idx)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8)\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "for key, val in batch.items():\n",
        "    print(f\"{key}: {val.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3Q1v_JL9Slk_"
      },
      "id": "3Q1v_JL9Slk_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weight Initialization\n",
        "\n",
        "Now that we have explored how to load different types of data, another crucial aspect of model training is weight initialization. There are several reasons why randomly initializing the weights of a neural network may not be ideal.\n",
        "\n",
        "**TO-DO**\n",
        "1. Can you state some of the reasons?\n",
        "2. Define a simple 2-3 layer MLP network which we will need for the following cells"
      ],
      "metadata": {
        "id": "TtqwRnoWFAwe"
      },
      "id": "TtqwRnoWFAwe"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n"
      ],
      "metadata": {
        "id": "DK9PrlDhFoEx"
      },
      "id": "DK9PrlDhFoEx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different types of Weight Initialization\n",
        "\n",
        "There exists several types of weight initialization techniques. Few of the popular ones are:\n",
        "1. Xavier Initialization\n",
        "2. Uniform Initialization\n",
        "3. Kaiming Initialization\n",
        "4. Orthogonal initilization\n",
        "\n",
        "**To-DO**\n",
        "\n",
        "1. Define functions for each weight initialization technique.\n"
      ],
      "metadata": {
        "id": "9ZeK6S0gMqoC"
      },
      "id": "9ZeK6S0gMqoC"
    },
    {
      "cell_type": "code",
      "source": [
        "def init_xavier(m):\n",
        "\n",
        "## TO-DO\n",
        "model = SimpleNet()\n",
        "model.apply(init_xavier)\n",
        "\n",
        "def init_uniform(m):\n",
        "## TO-DO\n",
        "model = SimpleNet()\n",
        "model.apply(init_uniform)\n",
        "\n",
        "def init_kaiming(m):\n",
        "## TO-DO\n",
        "model = SimpleNet()\n",
        "model.apply(init_kaiming)\n",
        "\n",
        "def init_orthogonal(m):\n",
        "\n",
        "## TO-DO\n",
        "model = SimpleNet()\n",
        "model.apply(init_orthogonal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzz-k-28HC8D",
        "outputId": "b174db65-6150-40ee-ba02-5ac76da7b543"
      },
      "id": "mzz-k-28HC8D",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleNet(\n",
              "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** TO-DO **\n",
        "\n",
        "1. Next, visualize the weight distribution of individual layers in your neural network, preferably the first layer, for each initialization technique.\n",
        "2. Do you notice any differences between the distributions? In addition, under what circumstances would you choose a specific type of initialization?"
      ],
      "metadata": {
        "id": "1_eUXg6kkhHx"
      },
      "id": "1_eUXg6kkhHx"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "model = SimpleNet()\n",
        "model.apply(init_uniform)\n",
        "weights = model.fc1.\n",
        "plt.hist(weights, bins=50)\n",
        "\n",
        "## TO-DO\n",
        "## Repeat for all the initialization techniques\n",
        "\n",
        "plt.legend([\"Uniform\", \"Xavier\", \"Orthogonal\", \"Kaiming\"])\n",
        "plt.title(\"Weight Distribution after Initialization\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nRfC_2oiHJI6"
      },
      "id": "nRfC_2oiHJI6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** TO-DO **\n",
        "\n",
        "1. Compare the difference in output variance between the different types of weight initialization. Hint: use output.var()"
      ],
      "metadata": {
        "id": "JDRAgD33sUj2"
      },
      "id": "JDRAgD33sUj2"
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_inits(init_fn, name):\n",
        "    model = SimpleNet()\n",
        "    model.apply(init_fn)\n",
        "    x = torch.randn(100, 784)\n",
        "    with torch.no_grad():\n",
        "\n",
        "    ## TO-DO\n",
        "    print(f\"{name} output variance: {}\")\n",
        "\n",
        "compare_inits(init_xavier, \"Xavier\")\n",
        "compare_inits(init_kaiming, \"Kaiming\")\n",
        "compare_inits(init_orthogonal, \"Orthogonal\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMbLJXh7HLY8",
        "outputId": "3386bfcb-a478-4d8d-da42-0111bbec1cd5"
      },
      "id": "eMbLJXh7HLY8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xavier output variance: 0.7054\n",
            "Kaiming output variance: 1.5789\n",
            "Orthogonal output variance: 0.2264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** TO-DO **\n",
        "\n",
        "The final step would be to bring all these components together to train a neural Network.\n",
        "\n",
        "1. Select a simple dataset from PyTorch dataset library and train a network network using different initializations. Report the empirical findings.\n",
        "  - Which initialization method facilitates faster convergence?\n",
        "  - Which method achieves the best overall performance?"
      ],
      "metadata": {
        "id": "T3b_fAyq1XwK"
      },
      "id": "T3b_fAyq1XwK"
    },
    {
      "cell_type": "code",
      "source": [
        "### TO-DO\n",
        "\n",
        "# Define your training and validation scripts\n",
        "# You are free to choose any optimizer such as SGD or ADAM\n",
        "# Train your neural networks intialized differently with the above mentioned weight initializers\n"
      ],
      "metadata": {
        "id": "D2uZs8mDhhBZ"
      },
      "id": "D2uZs8mDhhBZ",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mZd7QgQqiti"
      },
      "id": "6mZd7QgQqiti",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}